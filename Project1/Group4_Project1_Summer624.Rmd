---
title: "Group4_Project1_Summer624"
author: "Devin Teran"
date: "6/21/2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(xlsx)
library(dplyr)
library(fpp)
library(kableExtra)
library(ggplot2)
library(gridExtra)
library(urca)
```

## Getting Data
First we will read the data into a dataframe from the xls.
```{r get-data}
data <- read.xlsx2("/Users/devinteran/MSinDS/DATA624/DATA624/Project1/Data Set for Class.xls",sheetIndex = 1,colClasses = c('integer','character','double','double','double','double','double'),stringsAsFactors=FALSE)
```
## Exploratory Data Analysis
Our data represents 5 different groups where we are going to forecast data within each of these groups using specified variables from coluns 2-6.  We have 1622 data points within each group and will be forecasting 140 series points.  Here is a description of each columns:

**SeriesInd** - this provides the time element in our data.  It represents a frequency of 1.  
**group** - this will be what we are forecasted/our output prediction.  
**Var01, Var02, Var03, Var05, Var07** - these are to be used in different combinations in order to forecast 140 series data within each group
```{r view-data}
data[1:15,] %>%
  kbl() %>%
  kable_minimal()

```

## Cleaning Data
```{r clean-data}
S01 <- data %>% 
  mutate(date = as.Date(SeriesInd, origin = '1898-08-30')) %>%
  filter(SeriesInd < 43022 & group == 'S01') %>% 
  select (SeriesInd,date,Var01,Var02)

```

```{r view-cleaned-data}
S01[1:15,] %>%
  kbl() %>%
  kable_minimal()

```

## Missing Data
There are 2 rows within the group S01 that is missing a **Var01** value. 
```{r missing data}
library(visdat)
vis_dat(S01)
```

```{r missing-data-points}
S01[is.na(S01$Var01)|is.na(S01$Var02),]
```

```{r fix-missing-data}
prev_value <- S01[c(1536),'Var01']
S01_clean <- S01
S01_clean[is.na(S01_clean$Var01)|is.na(S01_clean$Var02),]$Var01 <- prev_value

```

## Visualize Data
```{r correlation}
require(scales)
S01_Var01 <- ggplot(S01_clean, aes(x=Var01)) +
  geom_histogram(bins=50,color='black',fill="#7fc97f") + 
  ggtitle("Group S01 Data") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 45))
S01_Var01_boxplot <- ggplot(S01_clean, aes(x=Var01)) +
  geom_boxplot(color='black',fill="#7fc97f") + 
  ggtitle("") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45))
S01_Var02 <- ggplot(S01_clean, aes(x=Var02)) +
  geom_histogram(bins=30,color='black',fill='#fdc086') + 
  scale_x_continuous(labels = comma) + 
  theme(axis.text.x = element_text(angle = 45))
S01_Var02_boxplot <- ggplot(S01_clean, aes(x=Var02)) +
  geom_boxplot(color='black',fill="#fdc086") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_x_continuous(labels = comma) + 
  theme(axis.text.x = element_text(angle = 45))
grid.arrange(S01_Var01,S01_Var01_boxplot,S01_Var02,S01_Var02_boxplot,nrow=2,widths=2:1)

```
  
* Variable 1 data has multiple peaks    
* Variable 02 is right skewed with many outliers    

## Decomposition - Trend, Seasonal, Error
```{r decomposition-Var01}
t <- ts(S01$Var01, start = 2010, end = 2014, frequency = 365)
t %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition of S01 data - Variable 01")
```
  
* There appears to be an increasing trend and clear seasonality  
  
```{r decomposition-Var02}
t <- ts(S01$Var02, start = 2010, end = 2014, frequency = 365)
t %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition of S01 data - Variable 02")
```
  
* There appears to be an decreasing trend and pontential seasonality    
  
## Time, ACF and PACF Plots    
### Variable 01  
```{r visualize-var01}
ggtsdisplay(S01_clean$Var01)
```
  
* Variable 01 data has a clear trend and is non-stationary data
* The ACF plot shows an initial large autocorrelation value that gradually decreases as the lag increases, which indicates a trend  
* The PACF shows a single significant value for lag 1.  This means the first lag explains all of the correlation that exists in the higher lags. This implies a consistent trend

### Differencing Variable 01 Data
#### Trend
From our previous plots we can see a clear trend.  Let's run a Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test in order to confirm this.  This test assumes that *Variable 01 data is stationary* and we are looking to reject that statement.  In order to reject that statement, we need to see that our test-statistic is less than 0.463.  
```{r var01-kpss-test}
S01_clean$Var01 %>% ur.kpss() %>% summary()
```

Here we see a test statistic of 16.0591 which is above 0.463 so we know we can reject the original statement that the *Variable 01 data is stationary*.  

From our KPSS test we confirmed that Variable 01 data is non-stationary and we need to differentiate it in an attempt to make it stationary.  Here we are differentiating the data and running the KPSS test again.  We see that our test-statistic is much lower and we can accept the assumption that *Variable 01 data after being differentiated once is now stationary*.  
```{r var01-differencing}
Var01_diff <- c(0,S01_clean$Var01 %>% diff())
S01_clean$Var01_diff <- Var01_diff

S01_clean$Var01_diff %>% ur.kpss() %>% summary()

```
#### Seasonal
To check for whether seasonal differencing is necessary we will run the function, **nsdiffs()**.  If there is seasonality in the data, the value returned will be greater than 0.64.  If it is less than 0.64, there is no seasonality.  
```{r season-Var01}
t <- ts(S01_clean$Var01,frequency=365)
nsdiffs(t)
```
No seasonal differencing is needed since the value is equal to 0.  This is interesting since visually it looked like there was seasonality in our decomposed plot seen above.  

### Variable 02
```{r visualize-var02}
ggtsdisplay(S01_clean$Var02)
```
  
* Variable 02 data is a little less clear but appears to have a negative trend and is non-stationary data  
* The ACF plot shows an initial large autocorrelation value that gradually decreases as the lag increases, which indicates a trend  
* The PACF shows a significant value for lag 1.  There also appears to be some seasonality since autocorrelations increase slightly as the lag increases.    

### Differencing Variable 02 Data
#### Trend
Just like we did with Variable 01, we are running the KPSS test and looking to reject the statement *Variable 02 is stationary*.  To do this the KPSS test-statistic must be larger than 0.463, which it is.  We reject the statement that Variable 02 data is stationary, which matches our previous theory.    
```{r var02-kpss-test}
S01_clean$Var02 %>% ur.kpss() %>% summary()
```

The KPSS test helped us confirm that Variable 02 data is non-stationary and we need to differentiate it as well.  Here we are differentiating the data and running the KPSS test again.  We see that our test-statistic is much lower and we can accept the assumption that *Variable 02 data after being differentiated once is now stationary*.  
```{r var02-differencing}
Var02_diff <- c(0,S01_clean$Var02 %>% diff())
S01_clean$Var02_diff <- Var02_diff

S01_clean$Var02_diff %>% ur.kpss() %>% summary()

```
#### Seasonal
To check for whether seasonal differencing is necessary we will run the function, **nsdiffs()**.  If there is seasonality in the data, the value returned will be greater than 0.64.  If it is less than 0.64, there is no seasonality.  

```{r season-Var02}
t <- ts(S01_clean$Var02,frequency=365)
nsdiffs(t)
```
No seasonal differencing is needed since the value is equal to 0.

## Splitting Data into Test & Training
Here we will use 80% of our data as training data and will reserve 20% of our data for testing.
```{r split-test-train}
break_num <- floor(nrow(S01_clean)*0.8)
train <- S01_clean[1:break_num,]
test  <- S01_clean[(break_num+1):nrow(S01_clean),]

```
## Time Series Plots

### Auto Arima - Variable 01
The first model we will test for Variable 01 is the **auto.arima** model with 1 difference.
```{r auto-arima-var-01}
S01_train_Var01 <- ts(select(train,Var01))

fit_var01_auto <- auto.arima(S01_train_Var01,d=1)
summary(fit_var01_auto)
```


### ETS - Variable 01  
Second we will use the exponential smoothing (ETS) model.  
```{r ets-var01}
fit_var01_ets <- ets(S01_train_Var01)
summary(fit_var01_ets)
```


### Forecast on Test Data - Variable 01
```{r forecast-variable01}
forecast_auto_var01 <- fit_var01_auto %>% forecast(nrow(train))
accuracy(forecast_auto_var01,S01_clean[1298:nrow(S01_clean),c('Var01')])

forecast_ets_var01 <- fit_var01_ets %>% forecast(nrow(train))
accuracy(forecast_ets_var01,S01_clean[1298:nrow(S01_clean),c('Var01')])
```

### Auto Arima - Variable 02
The first model we will test for Variable 02 is the **auto.arima** model with 1 difference.
```{r  auto-arima-var-02}
S01_train_Var02 <- ts(select(train,Var02))

fit_var02_auto <- auto.arima(S01_train_Var02,d=1)
summary(fit_var02_auto)

```

### ETS - Variable 02 Differentiated
Second we will use the exponential smoothing (ETS) model. 
```{r ets-var02}
fit_var02_ets <- ets(S01_train_Var02)
summary(fit_var02_ets)
```

### Forecast on Test Data - Variable 02
```{r forecast-variable02}
forecast_auto_var02 <- fit_var02_auto %>% forecast(nrow(test))
accuracy(forecast_auto_var02,S01_clean[1298:nrow(S01_clean),c('Var02')])

forecast_ets_var02 <- fit_var02_ets %>% forecast(nrow(test))
accuracy(forecast_ets_var02,S01_clean[1298:nrow(S01_clean),c('Var02')])
```

## Residuals of Models
```{r residuals_var01}
checkresiduals(fit_var01_auto)
```

```{r residuals_var02}
checkresiduals(fit_var02_auto)
```
## Forecasting out 140 Variables
Both auto.arima modeling methods produced the best models with the lowest MAPE values. For Variable 01 the model that was produce was ARIMA(0,1,1) with drift for Variable 02 the model is ARIMA(1,1,3).  
  
Now we will forecast out 140 periods using our selected models for Variable 01 and 02.
```{r var01-forecast}
final_forecast_auto_var01 <- fit_var01_auto %>% forecast(140)
autoplot(final_forecast_auto_var01)

```

```{r var02-forecast}
final_forecast_auto_var02 <- fit_var02_auto %>% forecast(140)
autoplot(final_forecast_auto_var02)
```


```{r export-to-excel}

S01_var01_prediction <- fit_var01_auto %>%
  forecast(h=140) %>%
  data.frame() %>%
  select(Point.Forecast) 


S01_var02_prediction <- fit_var02_auto %>%
  forecast(h=140) %>%
  data.frame() %>%
  select(Point.Forecast) 



predictions <- cbind(S01_var01_prediction,S01_var02_prediction)
file = 'Data624_project1_so1_predictions.xlsx'
#write.xlsx(predictions, file, sheetName = "S01", 
#  col.names = TRUE, row.names = TRUE, append = FALSE)


```
